{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ca3d1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    BertTokenizer, \n",
    "    BertForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc23f40",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load AG News dataset from Hugging Face\n",
    "dataset = load_dataset('ag_news')\n",
    "\n",
    "print(f\"  Dataset loaded successfully\")\n",
    "print(f\"  Train samples: {len(dataset['train']):,}\")\n",
    "print(f\"  Test samples:  {len(dataset['test']):,}\")\n",
    "\n",
    "\n",
    "TRAIN_SIZE = 10000 \n",
    "TEST_SIZE = 2000    \n",
    "\n",
    "print(f\"\\n Using subset to minimize disk space:\")\n",
    "print(f\"  Training: {TRAIN_SIZE:,} samples\")\n",
    "print(f\"  Testing:  {TEST_SIZE:,} samples\")\n",
    "\n",
    "# Create subsets\n",
    "train_dataset = dataset['train'].shuffle(seed=42).select(range(TRAIN_SIZE))\n",
    "test_dataset = dataset['test'].shuffle(seed=42).select(range(TEST_SIZE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9133066e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Display sample\n",
    "print(\"\\nSample data:\")\n",
    "for i in range(3):\n",
    "    example = train_dataset[i]\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"  Text:  {example['text'][:80]}...\")\n",
    "    print(f\"  Label: {example['label']} ({['World', 'Sports', 'Business', 'Sci/Tech'][example['label']]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507f9c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Class distribution\n",
    "train_labels = [example['label'] for example in train_dataset]\n",
    "class_names = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "print(\"\\nClass Distribution in Training Set:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    count = train_labels.count(i)\n",
    "    print(f\"  {name:12s}: {count:5d} ({count/len(train_labels)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86857f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Use bert-base-uncased \n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "print(f\" Tokenizer loaded: {model_name}\")\n",
    "\n",
    "# Load model for sequence classification (4 classes)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=4,\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "print(f\" Model loaded: {model_name}\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\" Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17a7ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples['text'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128  \n",
    "    )\n",
    "\n",
    "# Tokenize datasets\n",
    "print(\"Tokenizing training data...\")\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"Tokenizing test data...\")\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4490689",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Set format for PyTorch\n",
    "tokenized_train.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "tokenized_test.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "print(\" Tokenization complete\")\n",
    "print(f\"  Input shape: {tokenized_train[0]['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed2ef6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce522c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,             \n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,             \n",
    "    fp16=torch.cuda.is_available(),  \n",
    "    report_to='none'                \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe5820",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training configuration:\")\n",
    "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  Mixed precision (fp16): {training_args.fp16}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a932c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05988640",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n Training completed!\")\n",
    "print(f\"  Training loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"  Training time: {train_result.metrics['train_runtime']:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35199776",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "\n",
    "print(\"EVALUATION RESULTS: \")\n",
    "\n",
    "print(f\"Test Accuracy:  {eval_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Test F1-Score:  {eval_results['eval_f1']:.4f}\")\n",
    "print(f\"Test Loss:      {eval_results['eval_loss']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2e566",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "true_labels = predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08d073",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2239c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create confusion matrix heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names\n",
    ")\n",
    "plt.title('Confusion Matrix - BERT News Classifier', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdded9f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def predict_news_category(text, model, tokenizer, device):\n",
    "   \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(predictions, dim=-1).item()\n",
    "        confidence = predictions[0][predicted_class].item()\n",
    "    \n",
    "    return predicted_class, confidence, predictions[0].cpu().numpy()\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Test examples\n",
    "test_examples = [\n",
    "    \"Apple announces new iPhone with revolutionary camera technology\",\n",
    "    \"Stock market reaches all-time high amid economic recovery\",\n",
    "    \"Scientists discover new species in Amazon rainforest\",\n",
    "    \"Champions League final: Real Madrid defeats Manchester City 2-1\"\n",
    "]\n",
    "\n",
    "\n",
    "for i, text in enumerate(test_examples, 1):\n",
    "    predicted_class, confidence, probs = predict_news_category(text, model, tokenizer, device)\n",
    "    \n",
    "    print(f\"\\nExample {i}:\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Predicted: {class_names[predicted_class]} (Confidence: {confidence:.2%})\")\n",
    "    print(f\"All probabilities:\")\n",
    "    for j, (name, prob) in enumerate(zip(class_names, probs)):\n",
    "        print(f\"  {name:12s}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d412a16a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save model and tokenizer\n",
    "save_directory = './bert_news_classifier'\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd12f6b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate model size\n",
    "import os\n",
    "model_size = sum(\n",
    "    os.path.getsize(os.path.join(save_directory, f)) \n",
    "    for f in os.listdir(save_directory) \n",
    "    if os.path.isfile(os.path.join(save_directory, f))\n",
    ") / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "print(f\" Model size: {model_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd457c2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "deployment_script = '''\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load model\n",
    "model_path = './bert_news_classifier'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# Class names\n",
    "class_names = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "\n",
    "def classify_news(text):\n",
    "    \"\"\"Classify news headline\"\"\"\n",
    "    inputs = tokenizer(text, padding='max_length', truncation=True, \n",
    "                      max_length=128, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(predictions, dim=-1).item()\n",
    "        confidence = predictions[0][predicted_class].item()\n",
    "    \n",
    "    return {\n",
    "        'category': class_names[predicted_class],\n",
    "        'confidence': confidence,\n",
    "        'all_probabilities': {\n",
    "            name: prob.item() \n",
    "            for name, prob in zip(class_names, predictions[0])\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == '__main__':\n",
    "    example = \"NASA launches new Mars rover mission\"\n",
    "    result = classify_news(example)\n",
    "    print(f\"Text: {example}\")\n",
    "    print(f\"Category: {result['category']} ({result['confidence']:.2%})\")\n",
    "'''\n",
    "\n",
    "with open('deploy_classifier.py', 'w') as f:\n",
    "    f.write(deployment_script)\n",
    "\n",
    "print(\" Deployment script saved as 'deploy_classifier.py'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a4d76",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    \"\"\"Load model (cached)\"\"\"\n",
    "    model_path = './bert_news_classifier'\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "    model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "    model.eval()\n",
    "    return tokenizer, model\n",
    "\n",
    "# Load model\n",
    "tokenizer, model = load_model()\n",
    "class_names = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "\n",
    "# Page config\n",
    "st.set_page_config(page_title=\"News Classifier\", page_icon=\"\")\n",
    "\n",
    "# Title\n",
    "st.title(\" BERT News Topic Classifier\")\n",
    "st.markdown(\"Classify news headlines into: **World, Sports, Business, or Sci/Tech**\")\n",
    "\n",
    "# Input\n",
    "text_input = st.text_area(\n",
    "    \"Enter a news headline:\",\n",
    "    placeholder=\"e.g., Tesla announces new electric vehicle with 500-mile range\",\n",
    "    height=100\n",
    ")\n",
    "\n",
    "if st.button(\"Classify\", type=\"primary\"):\n",
    "    if text_input.strip():\n",
    "        # Predict\n",
    "        inputs = tokenizer(text_input, padding='max_length', truncation=True,\n",
    "                         max_length=128, return_tensors='pt')\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            predicted_class = torch.argmax(predictions, dim=-1).item()\n",
    "            confidence = predictions[0][predicted_class].item()\n",
    "        \n",
    "        # Display results\n",
    "        st.success(f\"**Predicted Category:** {class_names[predicted_class]}\")\n",
    "        st.metric(\"Confidence\", f\"{confidence:.2%}\")\n",
    "        \n",
    "        # Show all probabilities\n",
    "        st.subheader(\"All Predictions:\")\n",
    "        for name, prob in zip(class_names, predictions[0]):\n",
    "            st.progress(prob.item(), text=f\"{name}: {prob.item():.2%}\")\n",
    "    else:\n",
    "        st.warning(\"Please enter some text!\")\n",
    "\n",
    "# Example buttons\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"**Try these examples:**\")\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "examples = [\n",
    "    \"Stock market hits record high\",\n",
    "    \"Olympic champion breaks world record\",\n",
    "    \"New COVID vaccine shows promising results\",\n",
    "    \"Tech giant announces quarterly earnings\"\n",
    "]\n",
    "\n",
    "for i, example in enumerate(examples):\n",
    "    col = col1 if i % 2 == 0 else col2\n",
    "    if col.button(example, key=f\"ex_{i}\"):\n",
    "        st.rerun()\n",
    "'''\n",
    "\n",
    "with open('app_streamlit.py', 'w') as f:\n",
    "    f.write(streamlit_app)\n",
    "\n",
    "print(\" Streamlit app saved as 'app_streamlit.py'\")\n",
    "print(\" Run with: streamlit run app_streamlit.py\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
